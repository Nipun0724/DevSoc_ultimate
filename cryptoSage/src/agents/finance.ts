import { ChatOpenAI } from "@langchain/openai";
import { AIMessage, BaseMessage, HumanMessage, SystemMessage, ToolMessage } from "@langchain/core/messages";
import { Message } from "@/app/action";

import { ChatPromptTemplate, MessagesPlaceholder } from "@langchain/core/prompts";
import { AgentExecutor, createOpenAIToolsAgent } from "langchain/agents";
import { tools } from "@/agents/tools-crypto";
import { systemPrompt } from "@/agents/system-prompt";

// Initialize the language model with specific configurations
const llm = new ChatOpenAI({
  modelName: "gpt-4o",
  temperature: 0.1,
});

const MEMORY_KEY = "chat_history";

// Define the chat prompt structure
const prompt = ChatPromptTemplate.fromMessages([
  ["system", systemPrompt],
  new MessagesPlaceholder(MEMORY_KEY),
  ["user", "{input}"],
  new MessagesPlaceholder("agent_scratchpad"),
]);

/**
 * Executes the agent with the provided messages and returns the event stream.
 * @param messages - Array of BaseMessage objects representing the conversation history.
 * @returns The event stream generated by the agent.
 */
export async function runAgent(messages: BaseMessage[]) {
  const lastMessage = messages[messages.length - 1];

  // Create an OpenAI tools agent
  const agent = await createOpenAIToolsAgent({
    llm,
    tools,
    prompt,
  });

  // Initialize the agent executor
  const agentExecutor = new AgentExecutor({
    agent,
    tools,
  }).withConfig({ runName: "Agent" });

  // Stream events using the agent executor
  const eventStream = await agentExecutor.streamEvents(
    {
      input: lastMessage.content,
      chat_history: messages.slice(0, -1),
    },
    { version: "v1" }
  );

  return eventStream;
}

/**
 * Converts an array of Message objects into Langchain-compatible message types.
 * @param messages - Array of Message objects to convert.
 * @returns Array of Langchain-compatible message objects.
 */
export const convertMessages = (messages: Message[]) => {
  return messages.map((message) => {
    switch (message.role) {
      case "system":
        return new SystemMessage(message.content);
      case "user":
        return new HumanMessage(message.content);
      case "assistant":
        return new AIMessage(message.content);
      case "tool":
        return new ToolMessage({
          tool_call_id: message.id,
          content: message.content,
          additional_kwargs: {
            tool_calls: message.toolCalls,
          },
        });
      default:
        throw new Error(`Unsupported message role: ${message.role}`);
    }
  });
};